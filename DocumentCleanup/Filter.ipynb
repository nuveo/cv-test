{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pesquisando entre algoritmos de threshold/binarização com uma certa eficiencia esperada para imagens com tal nivel de ruido, tendo em vista que é perceptivel que algum método basico conhecido não teria tanto sucesso para o desafio encontrei um algoritmo conhecido por: Binarization Algorithm by Su et al.(http://doi.acm.org/10.1145/1815330.1815351) e com condigo presente em: https://gist.github.com/pebbie/2c17620e60c662950b02c4949b3010f2#file-su-py.\n",
    "# O método é capaz de filtrar o background estimando o contraste a partir do maximos e mininos locais. O algoritmo foi aplicado a imagens de documentos históricos, o que o indica como ótimo candidato de solução.\n",
    "# O algoritmo foi adaptado para utilização em meu código.\n",
    "\n",
    "\n",
    "nfns = [\n",
    "        lambda x: np.roll(x, -1, axis=0),\n",
    "        lambda x: np.roll(np.roll(x, 1, axis=1), -1, axis=0),\n",
    "        lambda x: np.roll(x, 1, axis=1),\n",
    "        lambda x: np.roll(np.roll(x, 1, axis=1), 1, axis=0),\n",
    "        lambda x: np.roll(x, 1, axis=0),\n",
    "        lambda x: np.roll(np.roll(x, -1, axis=1), 1, axis=0),\n",
    "        lambda x: np.roll(x, -1, axis=1),\n",
    "        lambda x: np.roll(np.roll(x, -1, axis=1), -1, axis=0)\n",
    "        ]\n",
    "\n",
    "def localminmax(img, fns):\n",
    "    mi = img.astype(np.float64)\n",
    "    ma = img.astype(np.float64)\n",
    "    for i in range(len(fns)):\n",
    "        rolled = fns[i](img)\n",
    "        mi = np.minimum(mi, rolled)\n",
    "        ma = np.maximum(ma, rolled)\n",
    "    result = (ma-mi)/(mi+ma+1e-16)\n",
    "    return result\n",
    "\n",
    "def numnb(bi, fns):\n",
    "    nb = bi.astype(np.float64)\n",
    "    i = np.zeros(bi.shape, nb.dtype)\n",
    "    i[bi==bi.max()] = 1\n",
    "    i[bi==bi.min()] = 0\n",
    "    for fn in fns:\n",
    "        nb += fn(i)\n",
    "    return nb\n",
    "\n",
    "def rescale(r,maxvalue=255):\n",
    "    mi = r.min()\n",
    "    return maxvalue*(r-mi)/(r.max()-mi)\n",
    "\n",
    "def binarize_Su_et_al(img):\n",
    "    gfn = nfns\n",
    "    N_MIN = 4\n",
    "\n",
    "    \n",
    "    g = img\n",
    "    I = g.astype(np.float64)\n",
    "\n",
    "\n",
    "    cimg = localminmax(I, gfn)\n",
    "    _, ocimg = cv2.threshold(rescale(cimg).astype(g.dtype), 0, 1, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    E = ocimg.astype(np.float64)\n",
    "\n",
    "\n",
    "    N_e = numnb(ocimg, gfn)\n",
    "    nbmask = N_e>0\n",
    "\n",
    "    E_mean = np.zeros(I.shape, dtype=np.float64)\n",
    "    for fn in gfn:\n",
    "        E_mean += fn(I)*fn(E)\n",
    "\n",
    "    E_mean[nbmask] /= N_e[nbmask]\n",
    "\n",
    "    E_var = np.zeros(I.shape, dtype=np.float64)\n",
    "    for fn in gfn:\n",
    "        tmp = (fn(I)-E_mean)*fn(E)\n",
    "        E_var += tmp*tmp\n",
    "\n",
    "    E_var[nbmask] /= N_e[nbmask]\n",
    "    E_std = np.sqrt(E_var)*.5\n",
    "\n",
    "    R = np.ones(I.shape)*255\n",
    "    R[(I<=E_mean+E_std)&(N_e>=N_MIN)] = 0\n",
    "\n",
    "    return R.astype(np.uint8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A solução se deu em três etapas.\n",
    "# A primeira, responsavel por remover o fundo da imagem (Algorithm by Su et al) e outras duas responsáveis por realizar transformações para alinhamento.\n",
    "# A primeira etapa de alinhamento foi a etapa de alinhamento horizontal. A ideia de alinhamento partiu da detecção de linha pela transformada probabilistica de Hough. Essa transformada recebe a imagem ja tranformada por outros três filtros: um filtro gaussiano, um filtro sharpen para evidenciar bordas e em seguida um filtro de canny é aplicado.\n",
    "# Com a detecção das linhas é possivel utilizar uma delas e verificar o alinhamento horizontal entre os dois vertices da reta. Para alinhamento então é aplicado warpAffine o qual realiza rotações de 1 grau na imagem no horario ou anti horaio até que os dois vertices se alinhem no eixo y, falando mais especificamente, se o vertice A for menor que B o algoritmo gira a imagem no sentido horário e vice e versa até os dois alinharem.\n",
    "# Para a segunda etapa de alinhamento, as linhas detectadas com esse mesmo processo também tem um bom uso, neste caso, após a transformação rigida feito pelo warpAffine agora realizamos uma transformação não rigida na imagem por meio de warpPerspective. A ideia é, dado duas linhas alinhadas em y, detectadas pelo algoritmo hough, julga-se que para um bom alinhamento, as cordenadas das duas pontas devem estar alinhadas em x, com testes foi verificado que um valor possivel, mas não ótimo, de ser usado ser 5 pixels de movimento para cada pixel de diferença entre as cordenadas das duas linhas. Um exemplo de execução: Se a linha superior tiver um pixel a frente da linha inferior, então o algoritmo deslocará 5 pixels para a esquerda os cantos superiores e 5 pixels para a direita os cantos inferiores na imagem final e vice e versa até as duas linhas alinharem.\n",
    "# O contra destas etapas de transformações é que devido a uma detecção imprecisa das linhas em alguns casos, a estimativa é afetada impossibilitando um resultado melhor alinhado.\n",
    "# Alguns outros detalhes sobre estas tecnicas encontram-se em minha breve aula sobre Image Stitching presente em: https://github.com/MarcosSoares10/ImageStitchingOpencvandDetailed\n",
    "\n",
    "\n",
    "#Edge enhance\n",
    "def sharpen_img(img):\n",
    "    kernel = np.array([[-1,-1,-1,-1,-1],\n",
    "                    [-1,2,2,2,-1],\n",
    "                    [-1,2,8,2,-1],\n",
    "                    [-2,2,2,2,-1],\n",
    "                    [-1,-1,-1,-1,-1]])/8.0\n",
    "    result=cv2.filter2D(img,-1,kernel)\n",
    "    return result\n",
    "\n",
    "def euclidian_distance(l):\n",
    "  result = math.sqrt((l[2] - l[0])**2+(l[3] - l[1])**2)\n",
    "  return result\n",
    "\n",
    "def execute_rotation(img,angle):\n",
    "  h, w = img.shape\n",
    "  center = w // 2, h // 2\n",
    "  matrix = cv2.getRotationMatrix2D(center, angle, 1)\n",
    "  rotated = cv2.warpAffine(img, matrix, (w, h), flags=cv2.INTER_NEAREST, borderValue=255)\n",
    "  return rotated\n",
    "\n",
    "def execute_transformation(img,aux,top_steps,bottom_steps):\n",
    "  #Taking the height and width of source and target image\n",
    "  height_src_img,width_src_img = img.shape\n",
    "  height_tgt_img,width_tgt_img = aux.shape\n",
    "\n",
    "  #Taking the corners of the images: top-left, bottom-left, bottom-right, top-right\n",
    "  array_corners_source_img = np.float32([[0,0],[0,height_src_img],[width_src_img,height_src_img],[width_src_img,0]])\n",
    "  array_corners_target_img = np.float32([[top_steps,0],[0+bottom_steps,height_tgt_img],[width_tgt_img+bottom_steps,height_tgt_img],[width_tgt_img+top_steps,0]])\n",
    "     \n",
    "  # Apply Perspective Transform Algorithm \n",
    "  matrix = cv2.getPerspectiveTransform(array_corners_source_img, array_corners_target_img) \n",
    "  result = cv2.warpPerspective(img, matrix, (width_tgt_img,height_tgt_img),flags=cv2.INTER_NEAREST, borderValue=255)\n",
    "  return result\n",
    "\n",
    "def evaluate_warpingAffine(img):\n",
    "  ksize = (10, 10) \n",
    "\n",
    "  final_angle = 0\n",
    "  angle = 0\n",
    "  execute = True\n",
    "\n",
    "  aux = cv2.blur(img, ksize)\n",
    "  aux = sharpen_img(aux)\n",
    "\n",
    "\n",
    "  edges = cv2.Canny(aux, 50, 200, None, 3)\n",
    "  hough_lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 50, None, 50, 10)\n",
    "\n",
    "\n",
    "  hough_distances = []\n",
    "\n",
    "  if hough_lines is not None:\n",
    "      for i in range(0, len(hough_lines)):\n",
    "          hough_distances.append((euclidian_distance(hough_lines[i][0]),i))\n",
    "\n",
    "\n",
    "  hough_distances.sort()\n",
    "  hough_distances.reverse()\n",
    "\n",
    "  l = hough_lines[hough_distances[0][1]][0]\n",
    "\n",
    "  while(execute):\n",
    "\n",
    "    hough_distances = []\n",
    "    #Verify if aligned on horizontal\n",
    "    if l[1] > l[3]:\n",
    "      angle = -1\n",
    "      final_angle += angle\n",
    "    elif l[1] < l[3]:\n",
    "      angle = 1\n",
    "      final_angle += angle\n",
    "    else:\n",
    "      execute = False\n",
    "    edges = execute_rotation(edges,angle)\n",
    "    hough_lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 50, None, 50, 10)\n",
    "    if hough_lines is not None:\n",
    "      for i in range(0, len(hough_lines)):\n",
    "          hough_distances.append((euclidian_distance(hough_lines[i][0]),i))\n",
    "    hough_distances.sort()\n",
    "    hough_distances.reverse()\n",
    "    l = hough_lines[hough_distances[0][1]][0]\n",
    "\n",
    "  return execute_rotation(img,final_angle),hough_distances,hough_lines,edges\n",
    "\n",
    "def evaluate_warpingPerspective(img,hough_distances,hough_lines,edges):\n",
    "   \n",
    "\n",
    "  final_top_steps = 0\n",
    "  final_bottom_steps = 0\n",
    "  \n",
    "  top_steps = 0\n",
    "  bottom_steps = 0\n",
    "  execute = True\n",
    "  aux = np.zeros((edges.shape[0]+80,edges.shape[1]+80), np.uint8)\n",
    "\n",
    "  l = hough_lines[hough_distances[0][1]][0]\n",
    "  l1 = hough_lines[hough_distances[1][1]][0]\n",
    "\n",
    "  while(execute):\n",
    "    hough_distances = []\n",
    "    #Verify if aligned on Vertical and horizontal\n",
    "    #also, condition execute transformation just if distance in from A to B in x is greater than\n",
    "    if (l[0] > l1[0]) and ((l[0] - l1[0]) > 3) and (l[1] < l[3]):\n",
    "      top_steps  += 5\n",
    "      bottom_steps -= 5\n",
    "      final_top_steps = top_steps\n",
    "      final_bottom_steps = bottom_steps\n",
    "    elif (l[0] < l1[0]) and  ((l1[0] - l[0]) > 3) and (l[1] > l[3]):\n",
    "      top_steps -= 5\n",
    "      bottom_steps += 5\n",
    "      final_top_steps = top_steps\n",
    "      final_bottom_steps = bottom_steps\n",
    "    else:\n",
    "      execute = False\n",
    "    \n",
    "    edges = execute_transformation(edges,aux,top_steps,bottom_steps) \n",
    "    hough_lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 50, None, 50, 10)\n",
    "    \n",
    "    if hough_lines is not None:\n",
    "      for i in range(0, len(hough_lines)):\n",
    "          hough_distances.append((euclidian_distance(hough_lines[i][0]),i))\n",
    "    \n",
    "    hough_distances.sort()\n",
    "    hough_distances.reverse()\n",
    "    \n",
    "    l = hough_lines[hough_distances[0][1]][0]\n",
    "    l1 = hough_lines[hough_distances[1][1]][0]\n",
    "\n",
    "\n",
    "  return execute_transformation(img,aux,final_top_steps,final_bottom_steps)\n",
    "  \n",
    "def execute_ALL(image_directory):\n",
    "\n",
    "  pathImages = os.listdir(image_directory)\n",
    "  pathImages.sort()\n",
    "\n",
    "  for index in range(len(pathImages)):\n",
    "    img = cv2.imread(image_directory+\"/\"+pathImages[index])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    aux = binarize_Su_et_al(gray)\n",
    "\n",
    "    rotated_img,hough_distances,hough_lines,edges = evaluate_warpingAffine(aux)\n",
    "    rotated_img = evaluate_warpingPerspective(rotated_img,hough_distances,hough_lines,edges)\n",
    "    \n",
    "\n",
    "\n",
    "    name, ext = os.path.splitext(pathImages[index])\n",
    "    cv2.imwrite(\"denoised_data/\"+name+\"_denoised_\"+ext, rotated_img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execute_ALL(\"noisy_data\")"
   ]
  }
 ]
}