{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANTE: Estou em fim de período no curso de Mestrado, com atividades pendentes. Não consegui\n",
    "# dedicar tempo suficiente para esta atividade. Aqui vai ser mais uma exemplo da ideia do que a \n",
    "# solução em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import metrics\n",
    "from statistics import median\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, jaccard_similarity_score, classification_report, \\\n",
    "        log_loss\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# todas as imagens serão redimensionadas para 128x128\n",
    "SHAPE = 128, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# função para gerar o conjunto de treinamento dado um diretório\n",
    "def train_set(folder):\n",
    "    TRAINING_TYPES = ['Disguise', 'Genuine', 'Reference', 'Simulated']\n",
    "\n",
    "#     leitura dos dados e geração das imagens binárias 128x128\n",
    "    def get_training_data():\n",
    "        data = {}\n",
    "        for type in TRAINING_TYPES:\n",
    "            data[type] = []\n",
    "            subfolder = os.path.join(folder, type)\n",
    "            for _, _, files in os.walk(subfolder):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(subfolder, file)\n",
    "                    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    img = ~cv2.resize(img, SHAPE, interpolation=cv2.INTER_AREA)\n",
    "                    data[type].append((file, img))\n",
    "        return data\n",
    "    \n",
    "#     As features usadas no treinamento serão os três tipos de distância de shapes (baseadas em Hu-\n",
    "#     Moments) definidas no OpenCV. Mais detalhes em: https://www.learnopencv.com/shape-matching-using-hu-moments-c-python/\n",
    "    def feature_extraction(data):\n",
    "        _, ref_list = zip(*data['Reference'])\n",
    "        tmp_data = { \"id\": [], \"dist1\": [], \"dist2\": [], \"dist3\": [], \"type\": [] }\n",
    "        for type in TRAINING_TYPES:\n",
    "            if type != 'Reference':\n",
    "                for item in data[type]:\n",
    "                    name, img = item\n",
    "                    name = name.split('.')[0]\n",
    "                    y = name[0] if name[0] != 'S' else 'F'\n",
    "                    id = int(name[1:])\n",
    "                    tmp_data['id'].append(id)\n",
    "                    for i in range(1, 4):\n",
    "                        dists = [cv2.matchShapes(img, ref_img, i, 0) for ref_img in ref_list]\n",
    "                        tmp_data['dist' + str(i)].append(median(dists))\n",
    "                    tmp_data['type'].append(y)\n",
    "        df = pd.DataFrame(tmp_data)\n",
    "        df = df.set_index('id')\n",
    "        df = df.sort_index()\n",
    "        return df\n",
    "    \n",
    "    data = get_training_data()\n",
    "    df = feature_extraction(data)\n",
    "    X = df[['dist1', 'dist2', 'dist3']]\n",
    "    y = df.type.values\n",
    "    X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos dados para teste\n",
    "def test_set(folder):\n",
    "    TEST_TYPES = ['Reference', 'Questioned']\n",
    "    \n",
    "    def get_test_data():\n",
    "        data = {}\n",
    "        for type in TEST_TYPES:\n",
    "            data[type] = []\n",
    "            subfolder = os.path.join(folder, type)\n",
    "            for _, _, files in os.walk(subfolder):\n",
    "                for file in files:\n",
    "                    file_path = os.path.join(subfolder, file)\n",
    "                    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "                    img = ~cv2.resize(img, SHAPE, interpolation=cv2.INTER_AREA)\n",
    "                    data[type].append((file, img))\n",
    "        return data\n",
    "    \n",
    "    def feature_extraction(data):\n",
    "        _, ref_list = zip(*data['Reference'])\n",
    "        tmp_data = { \"id\": [], \"dist1\": [], \"dist2\": [], \"dist3\": [] }\n",
    "        for item in data['Questioned']:\n",
    "            name, img = item\n",
    "            name = name.split('.')[0]\n",
    "            id = int(name[1:])\n",
    "            tmp_data['id'].append(id)\n",
    "            for i in range(1, 4):\n",
    "                dists = [cv2.matchShapes(img, ref_img, i, 0) for ref_img in ref_list]\n",
    "                tmp_data['dist' + str(i)].append(median(dists))\n",
    "        df = pd.DataFrame(tmp_data)\n",
    "        df = df.set_index('id')\n",
    "        df = df.sort_index()\n",
    "        return df\n",
    "    \n",
    "    data = get_test_data()\n",
    "    df = feature_extraction(data)\n",
    "    X = df[['dist1', 'dist2', 'dist3']]\n",
    "    X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classificador bobo, Regressão Logística com parâmetros default\n",
    "def load_classifier():\n",
    "    loaded_model = pickle.load(open('classifier.sav', 'rb'))\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, X_train, y_train):\n",
    "    return classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resposta no formato de uma String, conforme o README requer\n",
    "def predict(classifier, X_test):\n",
    "    return classifier.predict(X_test).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
