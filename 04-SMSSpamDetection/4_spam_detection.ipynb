{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Candidate**: André Oliveira Françani\n",
    "\n",
    "\n",
    "# SMS Ham-Spam Detection\n",
    "\n",
    "\n",
    "## Description\n",
    "\n",
    "The SMS Ham-Spam detection dataset is a set of SMS tagged messages that have been collected for SMS Spam research. It contains a set of 5,574 SMS messages in English, considering both train and test data. The tagging standard was defined as `ham` (legitimate) or `spam`. \n",
    "\n",
    "The `train` and `test` files are formatted using the standard of one message per line. Each line is composed by two columns: one with label (`ham` or `spam`) and other with the raw text. Here are some examples:\n",
    "\n",
    "```\n",
    "ham   What you doing?how are you?\n",
    "ham   Ok lar... Joking wif u oni...\n",
    "ham   dun say so early hor... U c already then say...\n",
    "ham   MY NO. IN LUTON 0125698789 RING ME IF UR AROUND! H*\n",
    "ham   Siva is in hostel aha:-.\n",
    "ham   Cos i was out shopping wif darren jus now n i called him 2 ask wat present...\n",
    "spam   FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time...\n",
    "spam   Sunshine Quiz! Win a super Sony DVD recorder if you canname the capital...\n",
    "spam   URGENT! Your Mobile No 07808726822 was awarded a L2,000 Bonus Caller Prize...\n",
    "```\n",
    "\n",
    "    Note: messages are not chronologically sorted.\n",
    "\n",
    "For evaluation purposes, the `test` dataset does not prosent the categories (`ham`, `spam`). Therefore, the `train` data is the full source of information for this test.\n",
    "\n",
    "## Objective\n",
    "\n",
    "The goal of the this test is to achieve a model that can correctly manage the incoming messages on SMS format (`ham` or `spam`). Considering a real scenario, assume that a regular person does not want to see a `spam` message. However, they accepts if a normal message (`ham`) is sometimes allocated at the `spam` box.\n",
    "\n",
    "## Important details\n",
    "\n",
    "- The dataset was split in order to have unseen data for analysis. We took 15% of the total data (randomly)\n",
    "- Replicate the data format for submission, i.e. the answer must be provided as a CSV file with the detect class in the first column and the text in the second column, similarly to what is provided in the `TrainingSet` file\n",
    "- The `TestSet` will be used for evalution, therefore the candidate must provide the first column with the predicted classes (`ham` or `spam`)\n",
    "- Pay attention to the real case scenario that was described in the Objective section. This may drive the problem solving strategy :wink:.\n",
    "- This test does not require a defined set of algorithms to be used. The candidate is free to choose any kind of data processing pipeline to reach the best answer.\n",
    "\n",
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve this problem, the first thing to do is to read and prepare the data using the *_pandas_* library and store it in a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:16.365384Z",
     "start_time": "2021-02-28T17:47:14.187207Z"
    }
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords #library nltk with common words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:16.412072Z",
     "start_time": "2021-02-28T17:47:16.368115Z"
    }
   },
   "outputs": [],
   "source": [
    "### GENERATE DATASET ###\n",
    "\n",
    "#reading and organizing trainig data\n",
    "training_set = pd.read_csv('TrainingSet/sms-hamspam-train.csv', sep='\\n', header=None)\n",
    "training_set = training_set[0].str.split('\\t',expand=True)\n",
    "training_set.columns = ['label','msg']\n",
    "training_set['usage'] = 'train' #create a new column with 'train'\n",
    "\n",
    "#binarizing label (spam = 1 and ham = 0)\n",
    "training_set.label = (training_set.label == 'spam').astype(int)\n",
    "\n",
    "\n",
    "#reading and organizing test data\n",
    "test_set = pd.read_csv('TestSet/sms-hamspam-test.csv', sep='\\n', header=None, names=['msg'])\n",
    "test_set['usage'] = 'test'      #create a new column with 'test'\n",
    "\n",
    "#concatenate training set and test set to do pre-process the data\n",
    "dataset = pd.concat([training_set, test_set]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following procedure is the **_tokenization_**, removing the punctuation and some common words, namely pronouns, articles, prepositions etc. These words can be found in *_stopwords_* of the nltk library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:19.414651Z",
     "start_time": "2021-02-28T17:47:16.415065Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\envs\\processos_seletivos\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#list with stopwords\n",
    "stopwords_list = stopwords.words('English') \n",
    "\n",
    "#list with all punctuation\n",
    "punctuation_str = string.punctuation     \n",
    "punctuation_list = [0]*len(punctuation_str)\n",
    "for i in range(len(punctuation_list)):\n",
    "    punctuation_list[i] = punctuation_str[i] \n",
    "    \n",
    "#remove words and punctuation of all messages\n",
    "idx_row = 0\n",
    "for sms in dataset.msg:\n",
    "    msg = [word for word in sms if word not in punctuation_list] #remove punctuation of message\n",
    "    msg = ''.join(msg)                                           #rebuild string\n",
    "    msg = msg.lower()\n",
    "    msg = [word for word in msg.split(' ') if word.lower() not in stopwords_list and word.isalpha()] #remove stopwords from message\n",
    "\n",
    "    dataset.msg[idx_row] = ' '.join(msg)\n",
    "    #dataset.msg[idx_row] = msg\n",
    "    idx_row += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data should be divided into train and test sets. Here, I got only 10% of test data because I want the more information as possible during training, since the real test data is already given in the exercise, however without label.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:19.424638Z",
     "start_time": "2021-02-28T17:47:19.416642Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(dataset.loc[dataset.usage == 'train','msg'], dataset.loc[dataset.usage == 'train','label'], test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, the **_Vectorization_** is performed since we are dealing with strings. Therefore we should encode the words into values to apply the machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:19.480905Z",
     "start_time": "2021-02-28T17:47:19.425635Z"
    }
   },
   "outputs": [],
   "source": [
    "#Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "vectorizer = TfidfVectorizer()              #build vectorizer\n",
    "X_train = vectorizer.fit_transform(X_train) #train vectorizer\n",
    "\n",
    "#Apply vectorizer in val set\n",
    "X_val = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T01:24:51.764918Z",
     "start_time": "2021-02-28T01:24:51.758969Z"
    }
   },
   "source": [
    "Now the classifier is built to classify the messages. The first approach is using a **Support Vector Machine (SVM)** to detect spam messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:20.934839Z",
     "start_time": "2021-02-28T17:47:19.481948Z"
    }
   },
   "outputs": [],
   "source": [
    "#Support Vector Machine (SVM)\n",
    "svm_model = svm.SVC(C=10) #tested with different C values\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "#Predict Class\n",
    "Y_pred = svm_model.predict(X_val)\n",
    "\n",
    "#Compute confusion matrix\n",
    "cf = metrics.confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "cf[0,0]": "392",
     "cf[0,1]": "0",
     "cf[1,0]": "12",
     "cf[1,1]": "69"
    }
   },
   "source": [
    "### Confusion Matrix - SVM: \n",
    "\n",
    "<!-- Spam = 1 \n",
    "<br> Ham = 0\n",
    "<br> <br> Type I error: rejecting the null hypothesis when it is true (False Positive). \n",
    "<br>Type II error: Accepting the null hypothesis when it is false (False Negative).\n",
    "\n",
    "<br> -->\n",
    "\n",
    "<!-- | | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | 392  (TN)| 0 (FP)|\n",
    "| **Actual: Spam** | 12 (FN) | 68   (TP)|\n",
    "\n",
    " -->\n",
    "\n",
    "| | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | {{cf[0,0]}}  (TN)| {{cf[0,1]}} (FP)|\n",
    "| **Actual: Spam** | {{cf[1,0]}} (FN) | {{cf[1,1]}}   (TP)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the goal of this test, a regular person does not want to see a spam message. However, they accept if a normal message (ham) is sometimes allocated at the spam box. This means that we accept more false positives (Type I error) than false negatives (Type II error).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next tested model is a **Naive Bayes** classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:20.970039Z",
     "start_time": "2021-02-28T17:47:20.962063Z"
    }
   },
   "outputs": [],
   "source": [
    "#Naive Bayes classifier\n",
    "nbc_model = MultinomialNB()\n",
    "nbc_model = nbc_model.fit(X_train, Y_train)\n",
    "\n",
    "#Predict Class\n",
    "Y_pred = nbc_model.predict(X_val)\n",
    "\n",
    "#Compute confusion matrix\n",
    "cf = metrics.confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "cf[0,0]": "392",
     "cf[0,1]": "0",
     "cf[1,0]": "18",
     "cf[1,1]": "63"
    }
   },
   "source": [
    "### Confusion Matrix - Naive Bayes: \n",
    "\n",
    "<!-- Spam = 1 \n",
    "<br> Ham = 0\n",
    "<br> <br> Type I error: rejecting the null hypothesis when it is true (False Positive). \n",
    "<br>Type II error: Accepting the null hypothesis when it is false (False Negative).\n",
    "\n",
    "<br> -->\n",
    "\n",
    "<!-- | | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | 392 (TN)| 0 (FP)|\n",
    "| **Actual: Spam** | 18 (FN) | 63   (TP)| -->\n",
    "\n",
    "| | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | {{cf[0,0]}}  (TN)| {{cf[0,1]}} (FP)|\n",
    "| **Actual: Spam** | {{cf[1,0]}} (FN) | {{cf[1,1]}}   (TP)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there were more false negatives using Naive Bayes, it can be concluded that the SVM had a better performance than the Naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next tested classifier is a **Decision Tree** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:21.286225Z",
     "start_time": "2021-02-28T17:47:20.996189Z"
    }
   },
   "outputs": [],
   "source": [
    "#Decision Tree classifier\n",
    "dtc_model = DecisionTreeClassifier(min_samples_split=7, random_state=111)\n",
    "dtc_model = dtc_model.fit(X_train, Y_train)\n",
    "\n",
    "#Predict Class\n",
    "Y_pred = dtc_model.predict(X_val)\n",
    "\n",
    "#Compute confusion matrix\n",
    "cf = metrics.confusion_matrix(Y_val, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "cf[0,0]": "383",
     "cf[0,1]": "9",
     "cf[1,0]": "17",
     "cf[1,1]": "64"
    }
   },
   "source": [
    "### Confusion Matrix - Decision Tree: \n",
    "\n",
    "<!-- Spam = 1 \n",
    "<br> Ham = 0\n",
    "<br> <br> Type I error: rejecting the null hypothesis when it is true (False Positive). \n",
    "<br>Type II error: Accepting the null hypothesis when it is false (False Negative).\n",
    "\n",
    "<br> -->\n",
    "\n",
    "<!-- | | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | 383  (TN)| 9 (FP)|\n",
    "| **Actual: Spam** | 17 (FN) | 64   (TP)| -->\n",
    "\n",
    "| | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | {{cf[0,0]}}  (TN)| {{cf[0,1]}} (FP)|\n",
    "| **Actual: Spam** | {{cf[1,0]}} (FN) | {{cf[1,1]}}   (TP)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last classifier tested is a **Random Forest** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:21.652276Z",
     "start_time": "2021-02-28T17:47:21.312217Z"
    }
   },
   "outputs": [],
   "source": [
    "#Random Forest classifier\n",
    "rfc_model = RandomForestClassifier(n_estimators=31, random_state=111)\n",
    "rfc_model = rfc_model.fit(X_train, Y_train)\n",
    "\n",
    "#Predict Class\n",
    "Y_pred = rfc_model.predict(X_val)\n",
    "\n",
    "#Compute confusion matrix\n",
    "cf = metrics.confusion_matrix(Y_val, Y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "cf[0,0]": "392",
     "cf[0,1]": "0",
     "cf[1,0]": "13",
     "cf[1,1]": "68"
    }
   },
   "source": [
    "### Confusion Matrix - Random Forest: \n",
    "\n",
    "<!-- Spam = 1 \n",
    "<br> Ham = 0\n",
    "<br> <br> Type I error: rejecting the null hypothesis when it is true (False Positive). \n",
    "<br>Type II error: Accepting the null hypothesis when it is false (False Negative). -->\n",
    "\n",
    "<br>\n",
    "\n",
    "<!-- | | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | 392  (TN)| 0 (FP)|\n",
    "| **Actual: Spam** | 13 (FN) | 68   (TP)|\n",
    " -->\n",
    "| | Predicted: Ham  | Predicted: Spam    |\n",
    "|---:|:-------------|:-----------|\n",
    "| **Actual:  Ham** | {{cf[0,0]}}  (TN)| {{cf[0,1]}} (FP)|\n",
    "| **Actual: Spam** | {{cf[1,0]}} (FN) | {{cf[1,1]}}   (TP)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing all models, the SVM had the best performance since it scored the lower false negatives and no false positives. Therefore, this model will be use to classify the given test messages in this exercise. The predicted results are saved in **_'sms-hamspam-test-solution.csv'_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:21.887098Z",
     "start_time": "2021-02-28T17:47:21.685353Z"
    }
   },
   "outputs": [],
   "source": [
    "#pre-process test data\n",
    "X_test = vectorizer.transform(dataset.loc[dataset.usage == 'test','msg']) #test vectorizer\n",
    "\n",
    "#predict test label\n",
    "Y_test_pred = pd.Series(svm_model.predict(X_test))\n",
    "\n",
    "#categorical label\n",
    "Y_test_pred[Y_test_pred == 1] = 'spam'\n",
    "Y_test_pred[Y_test_pred == 0] = 'ham'\n",
    "\n",
    "#make csv file\n",
    "save_file = pd.DataFrame(\n",
    "            {'label': Y_test_pred,\n",
    "             'message': test_set.msg})\n",
    "save_file.to_csv('sms-hamspam-test-solution.csv', index=False, header=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the generated file with the predicted class and visualize some messages detected as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:21.904042Z",
     "start_time": "2021-02-28T17:47:21.889047Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS 10 : Congratulations ur awarded 500 of CD vouchers or 125gift guaranteed & Free entry 2 100 wkly draw txt MUSIC to 87066 TnCs www.Ldew.com1win150ppmx3age16\n",
      "\n",
      "SMS 14 : Hi. Customer Loyalty Offer:The NEW Nokia6650 Mobile from ONLY £10 at TXTAUCTION! Txt word: START to No: 81151 & get yours Now! 4T&Ctxt TC 150p/MTmsg\n",
      "\n",
      "SMS 23 : Send a logo 2 ur lover - 2 names joined by a heart. Txt LOVE NAME1 NAME2 MOBNO eg LOVE ADAM EVE 07123456789 to 87077 Yahoo! POBox36504W45WQ TxtNO 4 no ads 150p\n",
      "\n",
      "SMS 44 : Want 2 get laid tonight? Want real Dogging locations sent direct 2 ur mob? Join the UK's largest Dogging Network bt Txting GRAVEL to 69888! Nt. ec2a. 31p.msg@150p\n",
      "\n",
      "SMS 47 : BangBabes Ur order is on the way. U SHOULD receive a Service Msg 2 download UR content. If U do not, GoTo wap. bangb. tv on UR mobile internet/service menu\n",
      "\n",
      "SMS 51 : URGENT! Your Mobile number has been awarded with a £2000 prize GUARANTEED. Call 09058094455 from land line. Claim 3030. Valid 12hrs only\n",
      "\n",
      "SMS 55 : FREE for 1st week! No1 Nokia tone 4 ur mobile every week just txt NOKIA to 8077 Get txting and tell ur mates. www.getzed.co.uk POBox 36504 W45WQ 16+ norm150p/tone\n",
      "\n",
      "SMS 56 : FreeMsg Why haven't you replied to my text? I'm Randy, sexy, female and live local. Luv to hear from u. Netcollex Ltd 08700621170150p per msg reply Stop to end\n",
      "\n",
      "SMS 57 : Congratulations ur awarded 500 of CD vouchers or 125gift guaranteed & Free entry 2 100 wkly draw txt MUSIC to 87066 TnCs www.Ldew.com1win150ppmx3age16\n",
      "\n",
      "SMS 59 : Congratulations ur awarded either £500 of CD gift vouchers & Free entry 2 our £100 weekly draw txt MUSIC to 87066 TnCs www.Ldew.com1win150ppmx3age16\n",
      "\n",
      "SMS 80 : URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
      "\n",
      "SMS 85 : T-Mobile customer you may now claim your FREE CAMERA PHONE upgrade & a pay & go sim card for your loyalty. Call on 0845 021 3680.Offer ends 28thFeb.T&C's apply\n",
      "\n",
      "SMS 92 : Orange customer, you may now claim your FREE CAMERA PHONE upgrade for your loyalty. Call now on 0207 153 9996. Offer ends 14thMarch. T&C's apply. Opt-out availa\n",
      "\n",
      "SMS 93 : PRIVATE! Your 2004 Account Statement for 07742676969 shows 786 unredeemed Bonus Points. To claim call 08719180248 Identifier Code: 45239 Expires\n",
      "\n",
      "SMS 95 : 22 days to kick off! For Euro2004 U will be kept up to date with the latest news and results daily. To be removed send GET TXT STOP to 83222\n",
      "\n",
      "SMS 103 : URGENT! Your Mobile No. was awarded £2000 Bonus Caller Prize on 5/9/03 This is our final try to contact U! Call from Landline 09064019788 BOX42WR29C, 150PPM\n",
      "\n",
      "SMS 105 : England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/ú1.20 POBOXox36504W45WQ 16+\n",
      "\n",
      "SMS 119 : You have won a guaranteed £200 award or even £1000 cashto claim UR award call free on 08000407165 (18+) 2 stop getstop on 88222 PHP. RG21 4JX\n",
      "\n",
      "SMS 125 : Dear Voucher Holder, 2 claim this weeks offer, at your PC go to http://www.e-tlp.co.uk/expressoffer Ts&Cs apply.2 stop texts txt STOP to 80062.\n",
      "\n",
      "SMS 148 : Will u meet ur dream partner soon? Is ur career off 2 a flyng start? 2 find out free, txt HORO followed by ur star sign, e. g. HORO ARIES\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test = pd.read_csv('sms-hamspam-test-solution.csv', sep='\\t', header=None, names=['label','msg'])\n",
    "spam_idx = pred_test[pred_test.label=='spam'].index\n",
    "\n",
    "#print the first 20 messages detected as spam\n",
    "for i in spam_idx[:20]:\n",
    "    print('SMS '+ str(i+1) + ' : '+ pred_test.loc[i,'msg'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Let's read now some of the ham messages to check if some of them are false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-28T17:47:21.911986Z",
     "start_time": "2021-02-28T17:47:21.905147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMS 1 : I know that my friend already told that.\n",
      "\n",
      "SMS 2 : It took Mr owl 3 licks\n",
      "\n",
      "SMS 3 : Dunno y u ask me.\n",
      "\n",
      "SMS 4 : K.k:)advance happy pongal.\n",
      "\n",
      "SMS 5 : I know but you need to get hotel now. I just got my invitation but i had to apologise. Cali is to sweet for me to come to some english bloke's weddin\n",
      "\n",
      "SMS 6 : Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;\n",
      "\n",
      "SMS 7 : Just got up. have to be out of the room very soon. …. i hadn't put the clocks back til at 8 i shouted at everyone to get up and then realised it was 7. wahay. another hour in bed.\n",
      "\n",
      "SMS 8 : Do well :)all will for little time. Thing of good times ahead:\n",
      "\n",
      "SMS 9 : 8 at the latest, g's still there if you can scrounge up some ammo and want to give the new ak a try\n",
      "\n",
      "SMS 11 : Hi Princess! Thank you for the pics. You are very pretty. How are you?\n",
      "\n",
      "SMS 12 : Not getting anywhere with this damn job hunting over here!\n",
      "\n",
      "SMS 13 : Good. Good job. I like entrepreneurs\n",
      "\n",
      "SMS 15 : Hi da:)how is the todays class?\n",
      "\n",
      "SMS 16 : No calls..messages..missed calls\n",
      "\n",
      "SMS 17 : Yo carlos, a few friends are already asking me about you, you working at all this weekend?\n",
      "\n",
      "SMS 18 : I'm sorry. I've joined the league of people that dont keep in touch. You mean a great deal to me. You have been a friend at all times even at great personal cost. Do have a great week.|\n",
      "\n",
      "SMS 19 : Haha mayb u're rite... U know me well. Da feeling of being liked by someone is gd lor. U faster go find one then all gals in our group attached liao.\n",
      "\n",
      "SMS 20 : Hmm .. Bits and pieces lol ... *sighs* ...\n",
      "\n",
      "SMS 21 : All was well until slightly disastrous class this pm with my fav darlings! Hope day off ok. Coffee wld be good as can't stay late tomorrow. Same time + place as always?\n",
      "\n",
      "SMS 22 : HEY GIRL. HOW R U? HOPE U R WELL ME AN DEL R BAK! AGAIN LONG TIME NO C! GIVE ME A CALL SUM TIME FROM LUCYxx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ham_idx = pred_test[pred_test.label=='ham'].index\n",
    "\n",
    "#print the first 20 messages classified as ham\n",
    "for i in ham_idx[:20]:\n",
    "    print('SMS '+ str(i+1) + ' : '+ pred_test.loc[i,'msg'] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the messages listed above, only one looks like spam (SMS 6). So it looks that the detector performed reasonably well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: Looking at some of the messages that are classified as spam, one can say that they really do look like spam, i.e. the SVM model worked pretty well at detecting spam."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
