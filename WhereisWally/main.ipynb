{"nbformat":4,"nbformat_minor":0,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"9Twn30gYf0JO","executionInfo":{"status":"ok","timestamp":1605422280321,"user_tz":180,"elapsed":682,"user":{"displayName":"Marcos Soares de Oliveira","photoUrl":"","userId":"15212616053731891531"}}},"source":["import cv2\n","import numpy as np\n","import json\n","import csv\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import os\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, UpSampling2D, Dropout, Conv2DTranspose, concatenate\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import tensorflow as tf\n","\n"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"qBdDhX-Mf0J_","executionInfo":{"status":"ok","timestamp":1605423572515,"user_tz":180,"elapsed":694,"user":{"displayName":"Marcos Soares de Oliveira","photoUrl":"","userId":"15212616053731891531"}}},"source":["#Data augmentation adaptado e modificado de https://github.com/FengYen-Chang/Data-Augmentation\n","import random\n","\n","\n","# avg blur minimum filter size is 3\n","def avg_blur(img, max_filiter_size = 3) :\n","\timg = img.astype(np.uint8)\n","\tif max_filiter_size >= 3 :\n","\t\tfilter_size = random.randint(3, max_filiter_size)\n","\t\tif filter_size % 2 == 0 :\n","\t\t\tfilter_size += 1\n","\t\tout = cv2.blur(img, (filter_size, filter_size))\n","\treturn out\n","\n","# gaussain blur minimum filter size is 3\n","# when sigma = 0 gaussain blur weight will compute by program\n","# when the sigma is more large the blur effect more obvious\n","\n","def gaussain_blur(img, max_filiter_size = 3, sigma = 0) :\n","\timg = img.astype(np.uint8)\n","\tif max_filiter_size >= 3 :\n","\t\tfilter_size = random.randint(3, max_filiter_size)\n","\t\tif filter_size % 2 == 0 :\n","\t\t\tfilter_size += 1\n","\t\t#print ('size = %d'% filter_size)\n","\t\tout = cv2.GaussianBlur(img, (filter_size, filter_size), sigma)\n","\treturn out\n","\n","def gaussain_noise(img, mean = 0, var = 0.1) :\n","\timg = img.astype(np.uint8)\n","\th, w, c = img.shape\n","\tsigma = var ** 0.5\n","\tgauss = np.random.normal(mean, sigma, (h, w, c))\n","\tgauss = gauss.reshape(h, w, c).astype(np.uint8)\n","\tnoisy = img + gauss\n","\treturn noisy\n","\n","# fill_pixel is 0(black) or 255(white)\n","def img_shift(img,mask, x_min_shift_piexl = -1, x_max_shift_piexl = 1, y_min_shift_piexl = -1, y_max_shift_piexl = 1, fill_pixel = 0):\n","  img = img.astype(np.uint8)\n","  h, w, c = img.shape\n","  out = np.zeros(img.shape)\n","  maskout = np.zeros(mask.shape)\n","\t\n","  if fill_pixel == 255:\n","    out[:, :] = 255\n","  out = out.astype(np.uint8)\n","  maskout = maskout.astype(np.uint8)\n","  \n","  move_x = random.randint(x_min_shift_piexl, x_max_shift_piexl)\n","  move_y = random.randint(y_min_shift_piexl, y_max_shift_piexl)\n"," \n","  if move_x >= 0 and move_y >= 0 :\n","    out[move_y:, move_x: ] = img[0: (h - move_y), 0: (w - move_x)]\n","    maskout[move_y:, move_x: ] = mask[0: (h - move_y), 0: (w - move_x)]\n","  elif move_x < 0 and move_y < 0 :\n","    out[0: (h + move_y), 0: (w + move_x)] = img[ - move_y:, - move_x:]\n","    maskout[0: (h + move_y), 0: (w + move_x)] = mask[ - move_y:, - move_x:]\n","  elif move_x >= 0 and move_y < 0 :\n","    out[0: (h + move_y), move_x:] = img[ - move_y:, 0: (w - move_x)]\n","    maskout[0: (h + move_y), move_x:] = mask[ - move_y:, 0: (w - move_x)]\n","  elif move_x < 0 and move_y >= 0 :\n","    out[move_y:, 0: (w + move_x)] = img[0 : (h - move_y), - move_x:]\n","    maskout[move_y:, 0: (w + move_x)] = mask[0 : (h - move_y), - move_x:]\n","    \n","  return out,maskout\n","\n","\n","# In img_flip func. it will random filp image\n","# when flip factor is 1 it will do hor. flip (Horizontal)\n","#\t\t\t\t\t  0            ver. flip (Vertical)\n","#\t\t\t\t\t -1\t\t\t   hor. + ver flip\n","def img_flip(img,mask):\n","  img = img.astype(np.uint8)\n","  flip_factor = random.randint(-1, 1)\n","  out = cv2.flip(img, flip_factor)\n","  maskout = cv2.flip(mask, flip_factor)\n","  return out,maskout\n","\n","\n","# change image contrast by hsv\n","def img_contrast(img, min_s, max_s, min_v, max_v) :\n","\timg = img.astype(np.uint8)\n","\thsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n","\t_s = random.randint(min_s, max_s)\n","\t_v = random.randint(min_v, max_v)\n","\tif _s >= 0 :\n","\t\thsv_img[:, :, 1] += _s\n","\telse :\n","\t\t_s = - _s\n","\t\thsv_img[:, :, 1] -= _s\n","\tif _v >= 0 :\n","\t\thsv_img[:, :, 2] += _v\n","\telse :\n","\t\t_v = - _v\n","\t\thsv_img[:, :, 2] += _v\n","\tout = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n","\treturn out\n","\n","#Edge enhance\n","def sharpen_img(img):\n","    kernel = np.array([[-1,-1,-1,-1,-1],\n","                    [-1,2,2,2,-1],\n","                    [-1,2,8,2,-1],\n","                    [-2,2,2,2,-1],\n","                    [-1,-1,-1,-1,-1]])/8.0\n","    result=cv2.filter2D(img,-1,kernel)\n","    return result\n","\n","\n","def create_augment_data(arrayimgs,arraymasks):\n","\n","  auxarrayimgs = arrayimgs.copy()\n","  auxarraymasks = arraymasks.copy()\n","\n","  # parameter for data augment functions\n","  _max_filiter_size = 5 \t\t#for avg_blur and gaussain_blur\n","  _sigma = 0 \t\t\t\t\t# for gaussain_blur\n","\n","  _mean = 0 \t\t\t\t\t# for gaussain_noise\n","  _var = 0.1\t\t\t\t\t# for gaussain_noise\n","\n","  _x_min_shift_piexl = -20 \t# for img_shift\n","  _x_max_shift_piexl = 20 \t# for img_shift\n","  _y_min_shift_piexl = -20 \t# for img_shift\n","  _y_max_shift_piexl = 20\t\t# for img_shift\n","  _fill_pixel = 255\t\t\t# for img_shift\n","\n","\n","  _min_s = -10\t\t\t\t# for img_contrast\n","  _max_s = 10\t\t\t\t\t# for img_contrast\n","  _min_v = -10\t\t\t\t# for img_contrast\n","  _max_v = 10\t\t\t\t\t# for img_contrast\n","\n","\n","\n","  for index in range(len(arrayimgs)):\n","    generate_quantity = 50\n","    while generate_quantity > 0:\n","      \n","      img = arrayimgs[index]\n","      mask = arraymasks[index]\n","\t\t\t\n","      if random.randint(0, 1) == 1:\n","        img = avg_blur(img, _max_filiter_size)\n","\n","      if random.randint(0, 1) == 1:\n","        img = gaussain_blur(img, _max_filiter_size, _sigma)\n","\n","      if random.randint(0, 1) == 1:\n","        img = gaussain_noise(img, _mean, _var)\n","\n","      if random.randint(0, 1) == 1:\n","        img,mask = img_shift(img, mask, _x_min_shift_piexl, _x_max_shift_piexl, _y_min_shift_piexl, _y_max_shift_piexl, _fill_pixel)\n","        \n","      if random.randint(0, 1) == 1:\n","        img,mask = img_flip(img, mask)\n","\n","      if random.randint(0, 1) == 1:\n","        img = img_contrast(img, _min_s, _max_s, _min_v, _max_v)\n","\n","      if random.randint(0, 1) == 1:\n","        img = sharpen_img(img)\n","      \n","      auxarrayimgs.append(img)\n","      auxarraymasks.append(mask)\n","\n","      generate_quantity -=1\n","\n","  return auxarrayimgs, auxarraymasks\n","\n"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"id":"by7ZG3wUf0Js","executionInfo":{"status":"ok","timestamp":1605423584026,"user_tz":180,"elapsed":1100,"user":{"displayName":"Marcos Soares de Oliveira","photoUrl":"","userId":"15212616053731891531"}}},"source":["#  Carregando arquivos de anotação json e capturando as coordenadas do objeto interesse.\n","#  Com tais pontos torna-se possivel criar mascaras binárias para um posterior treino de um modelo de IA.\n","#  Como melhor maneira de redimensionar a imagem é mais eficaz realizar corte na imagem, afinal como os arquivos de anotações\n","#em forma de cordenadas o processo de redimensionar teria maior custo, levando em conta que as anotações são importantes \n","#para a geração das mascaras.\n","#  Tendo em vista que de inicio ja temos as cordenadas da área de interesse ja é possivel calcular as centroides \n","#calculando moments: https://en.wikipedia.org/wiki/Image_moment.\n","#  A centroide do objeto alvo é então usada como ponto de inicio do raio de corte sob as imagens este definido manualmente.\n","#  Sabendo agora que o ponto de inicio é em uma centróide, para chegar ao tamanho desejado de redimensionamento X \n","#é utilizado o valor escolhido dividido por 2, afinal já é conhecido que um diametro é igual a duas vezes o raio, o valor X foi setado para 700\n","#por ser o menor lado de imagem dentre as que vi.\n","#  Agora veja bem, ao realinhar tal tipo de recorte tambem nos dá um outro tipo de desafio, o simples fato de que os objetos de interesse\n","#estarem proximos as bordas da imagem. Solução? Simples. Recorta apenas o possivel do lado que está na borda e compensa do outro lado.\n","# O modelo utilizado foi baseada em uma simples arquitetura unet exemplificado em https://www.kaggle.com/keegil/keras-u-net-starter-lb-0-277\n","#e como é de se esperar, a qualidade é baixa.\n","# O data augmentation ramdomiza as imagens de entrada entre varios algoritmos e filtros e estes por fim também randomizam as valores dos parametros.\n","\n","\n","def calculate_centroid(pts):\n","  M = cv2.moments(pts)\n","  cX = int(M[\"m10\"] / M[\"m00\"])\n","  cY = int(M[\"m01\"] / M[\"m00\"])\n","  return (cX, cY)\n","  \n","\n","def crop_ROI_img(img,crop_radius,centroidX,centroidY):\n","  crop = crop_radius/2\n","  \n","  if len(img.shape) == 2:\n","    height,width= img.shape\n","  else:\n","    height,width,_= img.shape\n","  \n","  left=0\n","  right=0\n","  top=0\n","  bottom=0\n","\n","\n","  growtoRight = centroidX + crop\n","  growtoLeft = centroidX - crop\n","  growtoTop = centroidY + crop\n","  growtoBottom = centroidY - crop\n","  \n","\n","  if (growtoRight > width): \n","    right = width\n","    left = int(growtoLeft - (growtoRight - right))\n","  elif (growtoLeft < 0): \n","    left = 0\n","    right = int(growtoRight + abs(growtoLeft))\n","  else: \n","    right = int(growtoRight)\n","    left = int(growtoLeft)\n","\n","  if (growtoTop > height):\n","    top = height\n","    bottom = int(growtoBottom - (crop - (top - centroidY)))\n","\n","  elif (growtoBottom < 0):\n","    top = int(growtoTop + abs(growtoBottom))\n","    bottom = 0\n","\n","  else: \n","    top = int(growtoTop)\n","    bottom = int(growtoBottom)\n","    \n","  newimage = img[bottom:top,left:right]  \n","  return newimage\n","\n","\n","def create_mask(img,pts):\n","  height,width,_= img.shape\n","  mask_img = np.zeros((height,width), np.uint8)\n","  mask_img = cv2.drawContours(mask_img ,[pts], -1, 255, -1)\n","  return mask_img\n","\n","def resizeimgsforModel(img,size):\n","  auximglist = []\n","  dim = (size, size)\n","  for item in img:\n","    resized = cv2.resize(item, dim, interpolation = cv2.INTER_AREA)\n","    auximglist.append(resized)\n","  return auximglist\n","\n","def load_dataset(path):\n","  imgfile = []\n","  maskfile = []\n","\n","  imgtrain = []\n","  masktrain = []\n","\n","  imgtest = []\n","  masktest = []\n","  \n","  pathImages = os.listdir(path)\n","  pathImages.sort()\n","\n","  crop_radius = 700 \n","\n","  for index in range(0,len(pathImages)-1,2):\n","    imgfile.append(path+\"/\"+pathImages[index])\n","    maskfile.append(path+\"/\"+pathImages[index+1])\n","\n","  X_train, X_test, y_train, y_test = train_test_split(imgfile, maskfile, test_size=0.2, random_state=42)\n","  \n","  #Loading Train\n","  for imgtr in range(len(X_train)):\n","    img = cv2.imread(X_train[imgtr])\n","    \n","    with open(y_train[imgtr]) as f:\n","      data = json.load(f)\n","    \n","    points = data['shapes'][0]\n","\n","    \n","    if len(points.get('points')) == 4:\n","      [x1,y1],[x2,y2],[x3,y3],[x4,y4] = points.get('points')\n","      pts = np.array([[x1,y1],[x2,y2],[x3,y3],[x4,y4]], np.int32)\n","      pts = pts.reshape((-1,1,2))\n","      (centroidX,centroidY) = calculate_centroid(pts)\n","\n","      resized_img = crop_ROI_img(img,crop_radius,centroidX,centroidY)\n","      imgtrain.append(resized_img)\n","\n","      maskimg = create_mask(img,pts)\n","      resized_mask = crop_ROI_img(maskimg,crop_radius,centroidX,centroidY)\n","      masktrain.append(resized_mask)\n","\n","    elif len(points.get('points')) == 3:\n","      [x1,y1],[x2,y2],[x3,y3]= points.get('points')\n","      pts = np.array([[x1,y1],[x2,y2],[x3,y3]], np.int32)\n","      pts = pts.reshape((-1,1,2))\n","      (centroidX,centroidY) = calculate_centroid(pts) \n","\n","      resized_img = crop_ROI_img(img,crop_radius,centroidX,centroidY)\n","      imgtrain.append(resized_img)\n","\n","      maskimg = create_mask(img,pts)\n","      resized_mask = crop_ROI_img(maskimg,crop_radius,centroidX,centroidY)\n","      masktrain.append(resized_mask)\n","  \n","  #Loading Test\n","  for imgte in range(len(X_test)):\n","    img = cv2.imread(X_test[imgte])\n","\n","    with open(y_test[imgte]) as f:\n","      data = json.load(f)\n","\n","    points = data['shapes'][0]\n","\n","    if len(points.get('points')) == 4:\n","      [x1,y1],[x2,y2],[x3,y3],[x4,y4] = points.get('points')\n","      pts = np.array([[x1,y1],[x2,y2],[x3,y3],[x4,y4]], np.int32)\n","      pts = pts.reshape((-1,1,2))\n","      (centroidX, centroidY) = calculate_centroid(pts)\n","\n","      resized_img = crop_ROI_img(img,crop_radius,centroidX,centroidY)\n","      imgtest.append(resized_img)\n","\n","      maskimg = create_mask(img,pts)\n","      resized_mask = crop_ROI_img(maskimg,crop_radius,centroidX,centroidY)\n","      masktest.append(resized_mask)\n","    \n","    elif len(points.get('points')) == 3:\n","      [x1,y1],[x2,y2],[x3,y3] = points.get('points')\n","      pts = np.array([[x1,y1],[x2,y2],[x3,y3]], np.int32)\n","      pts = pts.reshape((-1,1,2))\n","      (centroidX, centroidY) = calculate_centroid(pts)\n","\n","      resized_img = crop_ROI_img(img,crop_radius,centroidX,centroidY)\n","      imgtest.append(resized_img)\n","\n","      maskimg = create_mask(img,pts)\n","      resized_mask = crop_ROI_img(maskimg,crop_radius,centroidX,centroidY)\n","      masktest.append(resized_mask)\n","      \n","\n","  return (imgtrain,masktrain,imgtest,masktest)\n","\n","\n","\n","def create_model(image_size):\n","  inputs = Input(image_size)\n","  conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(inputs)\n","  conv1 = BatchNormalization()(conv1)\n","  conv1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv1)\n","  conv1 = BatchNormalization()(conv1)\n","  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) \n","\n","  conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool1)\n","  conv2 = BatchNormalization()(conv2)\n","  conv2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv2)\n","  conv2 = BatchNormalization()(conv2)\n","  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) \n","\n","  conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool2)\n","  conv3 = BatchNormalization()(conv3)\n","  conv3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv3)\n","  conv3 = BatchNormalization()(conv3)\n","  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3) \n","\n","  conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(pool3)\n","  conv4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv4)\n","\n","  up6 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4), conv3], axis=3) \n","  conv6 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up6)\n","  conv6 = BatchNormalization()(conv6)\n","  conv6 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv6)\n","  conv6 = BatchNormalization()(conv6)\n","\n","  up7 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv6), conv2], axis=3) \n","  conv7 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up7)\n","  conv7 = BatchNormalization()(conv7)\n","  conv7 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv7)\n","  conv7 = BatchNormalization()(conv7)\n","\n","  up8 = concatenate([Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(conv7), conv1], axis=3) \n","  conv8 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(up8)\n","  conv8 = BatchNormalization()(conv8)\n","  conv8 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(conv8)\n","  conv8 = BatchNormalization()(conv8)\n","\n","  conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv8)\n","\n","  model = Model(inputs=[inputs], outputs=[conv10])\n","\n","  return model"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIgjC5cWf0J3","executionInfo":{"status":"ok","timestamp":1605423586478,"user_tz":180,"elapsed":696,"user":{"displayName":"Marcos Soares de Oliveira","photoUrl":"","userId":"15212616053731891531"}}},"source":["def load_data(image_size):\n","    imgtrain,masktrain,imgtest,masktest = load_dataset(\"TrainingSet\")\n","    \n","    #Resizing images and masks for train models\n","    imgtrain = resizeimgsforModel(imgtrain,image_size)\n","    masktrain = resizeimgsforModel(masktrain,image_size)\n","\n","    #Data augmentation\n","    imgtrain,masktrain = create_augment_data(imgtrain,masktrain)\n","    imgtrain = np.array(imgtrain)\n","    masktrain = np.array(masktrain)\n","\n","    imgtest = resizeimgsforModel(imgtest,image_size)\n","    masktest = resizeimgsforModel(masktest,image_size)\n","    imgtest = np.array(imgtest)\n","    masktest = np.array(masktest)\n","\n","\n","    imgtrain = imgtrain.astype(np.float32)\n","    imgtest = imgtest.astype(np.float32)\n","\n","    imgtrain = imgtrain / 255.0\n","    imgtest = imgtest / 255.0\n","\n","    return (imgtrain, masktrain, imgtest, masktest)\n","\n"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"QqzaHTmCf0KN","executionInfo":{"status":"ok","timestamp":1605423590445,"user_tz":180,"elapsed":678,"user":{"displayName":"Marcos Soares de Oliveira","photoUrl":"","userId":"15212616053731891531"}}},"source":["def train_model(model,batch_size,train_steps,validation_steps,epochs,imgtrain,masktrain,imgtest,masktest):\n","    \n","    callbacks = [\n","                ModelCheckpoint(\"pretreinedmodels/model.val_accuracy={val_accuracy:.5f}.h5\", monitor='val_accuracy', verbose=1, save_best_model=True),\n","                EarlyStopping(monitor=\"val_accuracy\", patience=5, verbose=1)\n","            ]\n","\n","    model.fit(imgtrain,\n","            masktrain,\n","                steps_per_epoch=train_steps,\n","                validation_data=(imgtest,masktest),\n","                validation_steps=validation_steps,\n","                epochs=epochs,\n","                verbose=1,\n","                callbacks=callbacks\n","            )\n","            \n"],"execution_count":50,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"tKY7tCXPf0KG","executionInfo":{"status":"ok","timestamp":1605423593313,"user_tz":180,"elapsed":764,"user":{"displayName":"Marcos Soares de Oliveira","photoUrl":"","userId":"15212616053731891531"}}},"source":["def Build_TrainModel():\n","  image_size = 256\n","  modelinputsize = (image_size, image_size, 3)\n","\n","  imgtrain,masktrain,imgtest,masktest = load_data(image_size)\n","\n","  batch_size = 100\n","  train_steps=len(imgtrain) // batch_size\n","  validation_steps=len(imgtest)\n","  epochs = 10\n","\n","  model = create_model(modelinputsize)\n","  model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n","  model.summary()\n","  train_model(model,batch_size,train_steps,validation_steps,epochs,imgtrain,masktrain,imgtest,masktest)\n"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMePWH3EaHdF"},"source":["# Caso preferir treinar o modelo, abaixo está a chamada da função. Este processo tem bastante custo computacional nesse sentido não oriento utiliza-lo a não ser que seja em uma máquina com bastante recursos.\n","\n","#Build_TrainModel()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzQELuKZXoK9"},"source":["# Nesta seção você pode testar o método utilizando o arquivo salvo do modelo treinado anteriormente.\n","\n","import csv\n","import cv2\n","import numpy as np\n","import os\n","from tensorflow.keras.models import load_model\n","\n","import matplotlib.pyplot as plt\n","\n","def calculate_centroid(pts):\n","  M = cv2.moments(pts)\n","  if M[\"m10\"] == 0 or M[\"m00\"] == 0 or M[\"m01\"] ==0:\n","      return (0,0)\n","  else:\n","    cX = int(M[\"m10\"] / M[\"m00\"])\n","    cY = int(M[\"m01\"] / M[\"m00\"])\n","    return (cX, cY)\n","\n","\n","\n","def Segment_Find_On_AllImageDirectory(image_directory):\n","    modelpredict = load_model('pretreinedmodels/model.val_accuracy=0.80651.h5')\n","    pathImages = os.listdir(image_directory)\n","    pathImages.sort()\n","    result = []\n","\n","    if os.path.exists(\"results/wheres_wally_test.csv\"):\n","        os.remove(\"results/wheres_wally_test.csv\")\n","\n","    csvfile = open(\"results/wheres_wally_test.csv\", mode='w', encoding='utf-8')\n","\n","\n","    \n","\n","    for index in range(len(pathImages)):\n","        img = cv2.imread(image_directory+\"/\"+pathImages[index])\n","        img = img.astype(np.float32)\n","\n","        img = img / 255.0\n","        h, w, c = img.shape\n","\n","        h_aux = 256\n","        w_aux = 256\n","\n","        \n","        dim = (w_aux,h_aux)\n","        resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n","\n","        result_mask = modelpredict.predict(resized.reshape(1,h_aux,w_aux, c))\n","        result_mask = (result_mask > 0.9).astype(np.uint8)\n","\n","        dim = (w,h)\n","        result_mask = cv2.resize(result_mask.reshape(h_aux,w_aux), dim, interpolation = cv2.INTER_AREA)\n","        \n","        H2,W2 = result_mask.shape\n","        auximg = np.zeros((H2,W2), np.uint8)\n","        \n","        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n","        close = cv2.erode(result_mask.reshape(H2,W2),kernel,iterations = 5)\n","\n","        cnts = cv2.findContours(close, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n","        cx = 0 \n","        cy = 0 \n","\n","        \n","        for cnt in cnts:\n","            cx,cy = calculate_centroid(cnt)\n","            auximg = cv2.drawContours(auximg ,[cnt], -1, 255, -1)\n","        \n","        name, ext = os.path.splitext(pathImages[index])\n","        \n","        csvfile.write(pathImages[index]+\",\"+str(cx)+\",\"+str(cy))\n","        csvfile.write(\"\\n\")\n","\n","    \n","\n","        cv2.imwrite(\"results/segmentedmasks/\"+name+\"_mask_\"+ext, auximg)\n","    csvfile.close()\n","    \n","\n","\n","\n","\n","Segment_Find_On_AllImageDirectory(\"TestSet\")\n","\n","#O  Jupyter notebook costuma manter espaço usado em memória da GPU mesmo após uso, por esse motivo uma solução bem simples é encerrar o processo manualmente.\n","pid = os.getpid()\n","!kill -9 $pid\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"uSk1Ro6iXoLD"},"source":[""],"execution_count":null,"outputs":[]}]}