{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nome: Rafael Silva Del Lama\n",
    "# Email: rafael.lama@usp.br\n",
    "\n",
    "# Desafio: 02-FraudDetection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A abordagem adotada foi treinar um modelo de Rede Neural Convolucional que receba como entrada uma imagem de assinatura de referencia e uma imagem de assinatura questionada, e classifique a assinatura questionada como fraude, genuína ou disfarçada. \n",
    "\n",
    "Durante o treinamento, cada assinatura questionada foi apresentada a rede com todas as assinaturas de referencia. Já no teste, cada assinatura questionada será avaliada com cada uma das assinaturas de referencia e a classe atribuida a assinatura questionada será definida por voto majoritario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signature collection for testing contains 125 signatures. The signatures comprise:\n",
    "    - 25 reference signatures by the same writer “B”;\n",
    "    - 100 questioned signatures\n",
    "        - 3 genuine signatures written by the reference writer in his/her normal signature style\n",
    "        - 90 simulated signatures (written by 34 forgers freehand copying the signature characteristics of the reference writer); \n",
    "        - 7 disguised signatures written by the reference writer.\n",
    "        \n",
    "        \n",
    "The signatures of the test set are arranged according to the following folder structure:\n",
    "\n",
    "- **Reference:** Contains the reference signatures of another specimen author ‘B’. These signatures are used to train the classifier for verifying authorship of the specimen author ‘B’.\n",
    "- **Questioned:** Contains all the signatures for which the task is to verify authorship of the specimen author ‘B’.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função responsável por fazer a leitura das imagens.\n",
    "\n",
    "Parâmetros:\n",
    "    directory é o diretório contendo as contendo as pastas de cada classe com as respectivas imagens\n",
    "    input_shape (img_width, img_height, n_chanel)\n",
    "    \n",
    "Retornar 3 numpyArrays: \n",
    "    1º numpyArray contendo as informações das imagens\n",
    "    2º numpyArray contendo as classes\n",
    "    3º numpyArray contendo os labels das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_directory(directory, input_shape) :\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from scipy import misc\n",
    "    import cv2\n",
    "    \n",
    "\n",
    "    ## Leitura da base de dados\n",
    "    classes = glob.glob (directory + \"/*\" ) ## Array contendo o diretorio de cada classe\n",
    "    print(classes)\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = []\n",
    "    for i in range(len(classes)): # Para cada diretorio, lê todas as imagens\n",
    "        files = glob.glob (classes[i] + \"/*\") \n",
    "        for myFile in files: \n",
    "            im = Image.open(myFile)\n",
    "            image = np.array(im)\n",
    "            image_resized = misc.imresize(image, input_shape)\n",
    "            \n",
    "            if(len(image_resized.shape) == 3 and input_shape[2] == 1):\n",
    "                image_resized = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "                        \n",
    "            X.append (image_resized) \n",
    "            y.append (classes[i] .split('\\\\')[1])  ## Array contendo o labels das classes\n",
    "            labels.append(myFile.split('\\\\')[2].split('.')[0])\n",
    "            \n",
    "    del directory, classes, i, files, myFile, image # Remove as variaveis que nao serao mais utilizadas\n",
    "    \n",
    "    return np.asarray(X), np.asarray(y), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição de Funções\n",
    "\n",
    "### Função responsável por fazer a leitura das imagens.\n",
    "\n",
    "Parâmetros:\n",
    "    directory é o diretório contendo as contendo as pastas de cada classe com as respectivas imagens\n",
    "    input_shape (img_width, img_height, n_chanel)\n",
    "    \n",
    "Retornar 3 numpyArrays: \n",
    "    1º numpyArray contendo as informações das imagens\n",
    "    2º numpyArray contendo as classes\n",
    "    3º numpyArray contendo os labels das imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_directory(directory, input_shape) :\n",
    "    import glob\n",
    "    import numpy as np\n",
    "    from PIL import Image\n",
    "    from scipy import misc\n",
    "    import cv2\n",
    "    \n",
    "\n",
    "    ## Leitura da base de dados\n",
    "    classes = glob.glob (directory + \"/*\" ) ## Array contendo o diretorio de cada classe\n",
    "    print(classes)\n",
    "    X = []\n",
    "    y = []\n",
    "    labels = []\n",
    "    for i in range(len(classes)): # Para cada diretorio, lê todas as imagens\n",
    "        files = glob.glob (classes[i] + \"/*\") \n",
    "        for myFile in files: \n",
    "            im = Image.open(myFile)\n",
    "            image = np.array(im)\n",
    "            image_resized = misc.imresize(image, input_shape)\n",
    "            \n",
    "            if(len(image_resized.shape) == 3 and input_shape[2] == 1):\n",
    "                image_resized = cv2.cvtColor(image_resized, cv2.COLOR_BGR2GRAY)\n",
    "                        \n",
    "            X.append (image_resized) \n",
    "            y.append (classes[i] .split('\\\\')[1])  ## Array contendo o labels das classes\n",
    "            labels.append(myFile.split('\\\\')[2].split('.')[0])\n",
    "            \n",
    "    del directory, classes, i, files, myFile, image # Remove as variaveis que nao serao mais utilizadas\n",
    "    \n",
    "    return np.asarray(X), np.asarray(y), np.asarray(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura da rede e dos pesos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import model_from_json\n",
    "\n",
    "arquivo = open('nuveo.json', 'r')\n",
    "estrutura_rede = arquivo.read()\n",
    "arquivo.close()\n",
    "\n",
    "classificador = model_from_json(estrutura_rede)\n",
    "classificador.load_weights('nuveo.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width = 200\n",
    "img_height = 200\n",
    "img_chanels = 1\n",
    "\n",
    "test_dir = 'candidate-data/02-FraudDetection/TestSet'\n",
    "\n",
    "input_shape = (img_width, img_height, img_chanels) \n",
    "\n",
    "classes = ['Disguise', 'Genuine', 'Simulated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imagens_test, y_imagens_test, labels_imagens_test = read_images_from_directory(test_dir, input_shape)\n",
    "\n",
    "X_imagens_test = X_imagens_test.reshape(X_imagens_test.shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "\n",
    "X_imagens_test = X_imagens_test / 255\n",
    "\n",
    "X_reference_test = X_imagens_test[y_imagens_test == 'Reference']\n",
    "y_reference_test = y_imagens_test[y_imagens_test == 'Reference']\n",
    "\n",
    "X_questioned_test = X_imagens_test[y_imagens_test != 'Reference']\n",
    "y_questioned_test = y_imagens_test[y_imagens_test != 'Reference']\n",
    "\n",
    "print('Images Reference test: {}'.format(X_reference_test.shape))\n",
    "print('Images questioned test: {}'.format(X_questioned_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada assinatura questionada será avaliada com todas as assinaturas de referencia. \n",
    "A classe atribuida a assinatura será a classe majoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in range(len(X_questioned_test)):\n",
    "    D = 0\n",
    "    G = 0\n",
    "    F = 0\n",
    "    \n",
    "    for j in range(len(X_reference_test)):\n",
    "        predict = classificador.predict([X_reference_test[j].reshape(1, input_shape[0],input_shape[1], 1), \n",
    "                               X_questioned_test[i].reshape(1, input_shape[0],input_shape[1], 1)])\n",
    "        \n",
    "        predict = np.argmax(predict)\n",
    "        \n",
    "        if predict == 0:\n",
    "            D = D + 1\n",
    "        elif predict == 1:\n",
    "            G = G + 1\n",
    "        else:\n",
    "            F = F + 1\n",
    "            \n",
    "            \n",
    "    ## Majoritarian predict\n",
    "    if D >= G and D >= F:\n",
    "        predict = 0\n",
    "        \n",
    "    elif G >= D and G >= F:\n",
    "        predict = 1\n",
    "        \n",
    "    else:\n",
    "        predict = 2\n",
    "        \n",
    "    predictions.append({\"signature\": labels_imagens_test[i], \"class\": classes[predict],\n",
    "                       'Disguise': D / len(X_reference_test), 'Genuine': G / len(X_reference_test), \n",
    "                       'Simulated': F / len(X_reference_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predictions = pd.DataFrame(predictions, columns=['signature', 'class', 'Disguise', 'Genuine', 'Simulated'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simulated: {}\".format(len(predictions[predictions['class'] == 'Simulated'])))\n",
    "print(\"Disguise: {}\".format(len(predictions[predictions['class'] == 'Disguise'])))\n",
    "print(\"Genuine: {}\".format(len(predictions[predictions['class'] == 'Genuine'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
